{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de09e132",
   "metadata": {},
   "source": [
    "### 装包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9324b9b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting gym\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ab/b1/eb05a423eb801ab7d0715d6a3b28d92589e30b437052553df19ca2087240/gym-0.26.2.tar.gz (721 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gym) (1.22.4)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/25/26/d786c6bec30fe6110fd3d22c9a273a2a0e56c0b73b93e25ea1af5a53243b/gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Collecting importlib-metadata>=4.8.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/30/bb/bf2944b8b88c65b797acc2c6a2cb0fb817f7364debf0675792e034013858/importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (3.4.1)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (PEP 517): started\n",
      "  Building wheel for gym (PEP 517): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827646 sha256=e5f03ee53382353797fcbdc9e038f984cefd1d51df95236e7fb1484f2328c4a0\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\b3\\e5\\d4\\c8230c806aa3e259d427c5dce421c0e865993493c6dac4bd25\n",
      "Successfully built gym\n",
      "Installing collected packages: importlib-metadata, gym-notices, gym\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed gym-0.26.2 gym-notices-0.0.8 importlib-metadata-6.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b148cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pygame in c:\\programdata\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d493f8f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\ProgramData\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - box2d-py\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    box2d-py-2.3.8             |   py38h885f38d_5         448 KB  conda-forge\n",
      "    ca-certificates-2023.5.7   |       h56e8100_0         145 KB  conda-forge\n",
      "    certifi-2023.5.7           |     pyhd8ed1ab_0         149 KB  conda-forge\n",
      "    conda-4.14.0               |   py38haa244fe_0         1.0 MB  conda-forge\n",
      "    numpy-1.24.3               |   py38hf95b240_0          11 KB\n",
      "    numpy-base-1.24.3          |   py38h005ec55_0         6.1 MB\n",
      "    openssl-1.1.1l             |       h8ffe710_0         5.7 MB  conda-forge\n",
      "    python_abi-3.8             |           2_cp38           4 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        13.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  box2d-py           conda-forge/win-64::box2d-py-2.3.8-py38h885f38d_5\n",
      "  numpy-base         pkgs/main/win-64::numpy-base-1.24.3-py38h005ec55_0\n",
      "  python_abi         conda-forge/win-64::python_abi-3.8-2_cp38\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2022.07.19~ --> conda-forge::ca-certificates-2023.5.7-h56e8100_0\n",
      "  certifi            pkgs/main/win-64::certifi-2022.9.24-p~ --> conda-forge/noarch::certifi-2023.5.7-pyhd8ed1ab_0\n",
      "  conda              pkgs/main::conda-4.12.0-py38haa95532_0 --> conda-forge::conda-4.14.0-py38haa244fe_0\n",
      "  mkl                                 2021.2.0-haa95532_296 --> 2021.4.0-haa95532_640\n",
      "  numpy                               1.20.1-py38h34a8a5c_0 --> 1.24.3-py38hf95b240_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  openssl              pkgs/main::openssl-1.1.1q-h2bbff1b_0 --> conda-forge::openssl-1.1.1l-h8ffe710_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "numpy-base-1.24.3    | 6.1 MB    |            |   0% \n",
      "numpy-base-1.24.3    | 6.1 MB    |            |   0% \n",
      "numpy-base-1.24.3    | 6.1 MB    |            |   1% \n",
      "numpy-base-1.24.3    | 6.1 MB    | 2          |   2% \n",
      "numpy-base-1.24.3    | 6.1 MB    | 4          |   5% \n",
      "numpy-base-1.24.3    | 6.1 MB    | 6          |   7% \n",
      "numpy-base-1.24.3    | 6.1 MB    | 8          |   8% \n",
      "numpy-base-1.24.3    | 6.1 MB    | 9          |  10% \n",
      "numpy-base-1.24.3    | 6.1 MB    | #7         |  17% \n",
      "numpy-base-1.24.3    | 6.1 MB    | ##3        |  24% \n",
      "numpy-base-1.24.3    | 6.1 MB    | ##6        |  26% \n",
      "numpy-base-1.24.3    | 6.1 MB    | ####1      |  42% \n",
      "numpy-base-1.24.3    | 6.1 MB    | ####9      |  49% \n",
      "numpy-base-1.24.3    | 6.1 MB    | #####4     |  55% \n",
      "numpy-base-1.24.3    | 6.1 MB    | ######8    |  68% \n",
      "numpy-base-1.24.3    | 6.1 MB    | ########2  |  83% \n",
      "numpy-base-1.24.3    | 6.1 MB    | #########1 |  92% \n",
      "numpy-base-1.24.3    | 6.1 MB    | #########9 |  99% \n",
      "numpy-base-1.24.3    | 6.1 MB    | ########## | 100% \n",
      "\n",
      "openssl-1.1.1l       | 5.7 MB    |            |   0% \n",
      "openssl-1.1.1l       | 5.7 MB    |            |   0% \n",
      "openssl-1.1.1l       | 5.7 MB    | 1          |   2% \n",
      "openssl-1.1.1l       | 5.7 MB    | 3          |   3% \n",
      "openssl-1.1.1l       | 5.7 MB    | 4          |   5% \n",
      "openssl-1.1.1l       | 5.7 MB    | 5          |   5% \n",
      "openssl-1.1.1l       | 5.7 MB    | 9          |   9% \n",
      "openssl-1.1.1l       | 5.7 MB    | #3         |  13% \n",
      "openssl-1.1.1l       | 5.7 MB    | #7         |  18% \n",
      "openssl-1.1.1l       | 5.7 MB    | #9         |  20% \n",
      "openssl-1.1.1l       | 5.7 MB    | ##6        |  26% \n",
      "openssl-1.1.1l       | 5.7 MB    | ###9       |  39% \n",
      "openssl-1.1.1l       | 5.7 MB    | ####5      |  45% \n",
      "openssl-1.1.1l       | 5.7 MB    | #####1     |  51% \n",
      "openssl-1.1.1l       | 5.7 MB    | ######4    |  64% \n",
      "openssl-1.1.1l       | 5.7 MB    | #######9   |  79% \n",
      "openssl-1.1.1l       | 5.7 MB    | ########8  |  89% \n",
      "openssl-1.1.1l       | 5.7 MB    | #########6 |  97% \n",
      "openssl-1.1.1l       | 5.7 MB    | ########## | 100% \n",
      "\n",
      "numpy-1.24.3         | 11 KB     |            |   0% \n",
      "numpy-1.24.3         | 11 KB     | ########## | 100% \n",
      "numpy-1.24.3         | 11 KB     | ########## | 100% \n",
      "\n",
      "certifi-2023.5.7     | 149 KB    |            |   0% \n",
      "certifi-2023.5.7     | 149 KB    | #          |  11% \n",
      "certifi-2023.5.7     | 149 KB    | ########## | 100% \n",
      "\n",
      "box2d-py-2.3.8       | 448 KB    |            |   0% \n",
      "box2d-py-2.3.8       | 448 KB    | 3          |   4% \n",
      "box2d-py-2.3.8       | 448 KB    | #########2 |  93% \n",
      "box2d-py-2.3.8       | 448 KB    | ########## | 100% \n",
      "\n",
      "conda-4.14.0         | 1.0 MB    |            |   0% \n",
      "conda-4.14.0         | 1.0 MB    | 1          |   2% \n",
      "conda-4.14.0         | 1.0 MB    | #2         |  12% \n",
      "conda-4.14.0         | 1.0 MB    | ####4      |  45% \n",
      "conda-4.14.0         | 1.0 MB    | ########## | 100% \n",
      "conda-4.14.0         | 1.0 MB    | ########## | 100% \n",
      "\n",
      "python_abi-3.8       | 4 KB      |            |   0% \n",
      "python_abi-3.8       | 4 KB      | ########## | 100% \n",
      "python_abi-3.8       | 4 KB      | ########## | 100% \n",
      "\n",
      "ca-certificates-2023 | 145 KB    |            |   0% \n",
      "ca-certificates-2023 | 145 KB    | #1         |  11% \n",
      "ca-certificates-2023 | 145 KB    | ##2        |  22% \n",
      "ca-certificates-2023 | 145 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/win-64::anaconda==custom=py38_1\n",
      "  - defaults/win-64::astropy==4.2.1=py38h2bbff1b_1\n",
      "  - defaults/win-64::bkcharts==0.2=py38_0\n",
      "  - defaults/win-64::bokeh==2.3.2=py38haa95532_0\n",
      "  - defaults/win-64::bottleneck==1.3.2=py38h2a96729_1\n",
      "  - defaults/noarch::dask==2021.4.0=pyhd3eb1b0_0\n",
      "  - defaults/win-64::h5py==2.10.0=py38h5e291fa_0\n",
      "  - defaults/win-64::imagecodecs==2021.3.31=py38h5da4933_0\n",
      "  - defaults/noarch::imageio==2.9.0=pyhd3eb1b0_0\n",
      "  - defaults/win-64::matplotlib==3.3.4=py38haa95532_0\n",
      "  - defaults/win-64::matplotlib-base==3.3.4=py38h49ac443_0\n",
      "  - defaults/win-64::mkl_fft==1.3.0=py38h277e83a_2\n",
      "  - defaults/win-64::mkl_random==1.2.1=py38hf11a4ad_2\n",
      "  - defaults/win-64::numba==0.53.1=py38hf11a4ad_0\n",
      "  - defaults/win-64::numexpr==2.7.3=py38hb80d3ca_1\n",
      "  - defaults/win-64::numpy==1.20.1=py38h34a8a5c_0\n",
      "  - defaults/win-64::pandas==1.2.4=py38hd77b12b_0\n",
      "  - defaults/win-64::patsy==0.5.1=py38_0\n",
      "  - defaults/win-64::pyerfa==1.7.3=py38h2bbff1b_0\n",
      "  - defaults/win-64::pytables==3.6.1=py38ha5be198_0\n",
      "  - defaults/win-64::pywavelets==1.1.1=py38he774522_2\n",
      "  - defaults/win-64::scikit-image==0.18.1=py38hf11a4ad_0\n",
      "  - defaults/win-64::scikit-learn==0.24.1=py38hf11a4ad_0\n",
      "  - defaults/win-64::scipy==1.6.2=py38h66253e8_1\n",
      "  - defaults/noarch::seaborn==0.11.1=pyhd3eb1b0_0\n",
      "  - defaults/win-64::statsmodels==0.12.2=py38h2bbff1b_0\n",
      "  - defaults/noarch::tifffile==2021.4.8=pyhd3eb1b0_2\n",
      "  - defaults/win-64::_anaconda_depends==2020.07=py38_0\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 23.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge box2d-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f375ff",
   "metadata": {},
   "source": [
    "### 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe2f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de07bc8",
   "metadata": {},
   "source": [
    "### 准备环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2ce2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "# 网上提到该设置可能有其他风险"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d31ef30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#准备环境\n",
    "seed = 543\n",
    "def fix(env, seed):\n",
    "    env.action_space.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "import gym\n",
    "import random\n",
    "env = gym.make('LunarLander-v2' ,render_mode='rgb_array')\n",
    "fix(env, seed) # fix the environment Do not revise this !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40c29d1",
   "metadata": {},
   "source": [
    "下面是采用代码去输出 环境的 观测值，一个8维向量，动作是一个标量，4选一。\n",
    "\n",
    " - 该环境共有 8 个观测值，分别是： 水平坐标 x； 垂直坐标 y； 水平速度； 垂直速度； 角度； 角速度； 腿1触地； 腿2触地；\n",
    " - 可以采取四种离散的行动，分别是： 0 代表不采取任何行动 1.代表主引擎向左喷射 2 .代表主引擎向下喷射 3 .代表主引擎向右喷射\n",
    " - 环境中的 reward 大致是这样计算： 小艇坠毁得到 -100 分； 小艇在黄旗帜之间成功着地则得 100~140 分； 喷射主引擎（向下喷火）每次 -0.3 分； 小艇最终完全静止则再得 100 分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad75e36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-1.5       -1.5       -5.        -5.        -3.1415927 -5.\n",
      " -0.        -0.       ], [1.5       1.5       5.        5.        3.1415927 5.        1.\n",
      " 1.       ], (8,), float32)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85461c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae9d087f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.00629015,  1.3999223 ,  0.6371138 , -0.48880967, -0.00728197,\n",
      "       -0.14431562,  0.        ,  0.        ], dtype=float32), {})\n"
     ]
    }
   ],
   "source": [
    "initial_state = env.reset()\n",
    "print(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d11b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "random_action = env.action_space.sample()\n",
    "print(random_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a883931",
   "metadata": {},
   "source": [
    "### 随机动作玩5把"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a0440d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "img = plt.imshow(env.render())\n",
    "\n",
    "done = False\n",
    "rewords = []\n",
    "for i in range(5):\n",
    "    env.reset()[0]\n",
    "    img = plt.imshow(env.render())\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, _ , _= env.step(action)\n",
    "        total_reward += reward\n",
    "        img.set_data(env.render())\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "    rewords.append(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed408c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-200.08271333807346,\n",
       " -165.85066090041815,\n",
       " -209.26018892719014,\n",
       " -178.0866931381321,\n",
       " -73.61516505716682]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47234ce0",
   "metadata": {},
   "source": [
    "### 搭建PPO agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17eee256",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.is_terminals = []\n",
    "\n",
    "    def clear_memory(self):\n",
    "        del self.actions[:]\n",
    "        del self.states[:]\n",
    "        del self.logprobs[:]\n",
    "        del self.rewards[:]\n",
    "        del self.is_terminals[:]\n",
    "\n",
    "class ActorCriticDiscrete(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, n_latent_var):\n",
    "        super(ActorCriticDiscrete, self).__init__()\n",
    "\n",
    "        # actor\n",
    "        self.action_layer = nn.Sequential(\n",
    "                nn.Linear(state_dim, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, action_dim),\n",
    "                nn.Softmax(dim=-1)\n",
    "                )\n",
    "\n",
    "        # critic\n",
    "        self.value_layer = nn.Sequential(\n",
    "               nn.Linear(state_dim, 128),\n",
    "               nn.ReLU(),\n",
    "               nn.Linear(128, 64),\n",
    "               nn.ReLU(),\n",
    "               nn.Linear(64, 1)\n",
    "               )\n",
    "\n",
    "    def act(self, state, memory):\n",
    "        state = torch.from_numpy(state).float()\n",
    "        action_probs = self.action_layer(state)\n",
    "        dist = Categorical(action_probs)\n",
    "        action = dist.sample()\n",
    "\n",
    "        memory.states.append(state)\n",
    "        memory.actions.append(action)\n",
    "        memory.logprobs.append(dist.log_prob(action))\n",
    "\n",
    "        return action.item()\n",
    "\n",
    "    def evaluate(self, state, action):\n",
    "        action_probs = self.action_layer(state)\n",
    "        dist = Categorical(action_probs)\n",
    "\n",
    "        action_logprobs = dist.log_prob(action)\n",
    "        dist_entropy = dist.entropy()\n",
    "\n",
    "        state_value = self.value_layer(state)\n",
    "\n",
    "        return action_logprobs, torch.squeeze(state_value), dist_entropy\n",
    "\n",
    "class PPOAgent:\n",
    "    def __init__(self, state_dim, action_dim, n_latent_var, lr, betas, gamma, K_epochs, eps_clip):\n",
    "        self.lr = lr\n",
    "        self.betas = betas\n",
    "        self.gamma = gamma\n",
    "        self.eps_clip = eps_clip\n",
    "        self.K_epochs = K_epochs\n",
    "        self.timestep = 0\n",
    "        self.memory = Memory()\n",
    "\n",
    "        self.policy = ActorCriticDiscrete(state_dim, action_dim, n_latent_var)\n",
    "        self.optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr, betas=betas)\n",
    "        self.policy_old = ActorCriticDiscrete(state_dim, action_dim, n_latent_var)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "        self.MseLoss = nn.MSELoss()\n",
    "\n",
    "    def update(self):   \n",
    "        # Monte Carlo estimate of state rewards:\n",
    "        rewards = []\n",
    "        discounted_reward = 0\n",
    "        for reward, is_terminal in zip(reversed(self.memory.rewards), reversed(self.memory.is_terminals)):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
    "            rewards.insert(0, discounted_reward)\n",
    "\n",
    "        # Normalizing the rewards:\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-5)\n",
    "\n",
    "        # convert list to tensor\n",
    "        old_states = torch.stack(self.memory.states).detach()\n",
    "        old_actions = torch.stack(self.memory.actions).detach()\n",
    "        old_logprobs = torch.stack(self.memory.logprobs).detach()\n",
    "\n",
    "        # Optimize policy for K epochs:\n",
    "        for _ in range(self.K_epochs):\n",
    "            # Evaluating old actions and values : 新策略 重用 旧样本进行训练 \n",
    "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
    "\n",
    "            # Finding the ratio (pi_theta / pi_theta__old): \n",
    "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
    "\n",
    "            # Finding Surrogate Loss:计算优势值\n",
    "            advantages = rewards - state_values.detach()\n",
    "            surr1 = ratios * advantages ###  重要性采样的思想，确保新的策略函数和旧策略函数的分布差异不大\n",
    "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages ### 采样clip的方式过滤掉一些新旧策略相差较大的样本\n",
    "            loss = -torch.min(surr1, surr2)  + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
    "\n",
    "            # take gradient step\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        # Copy new weights into old policy:\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "    def step(self, reward, done):\n",
    "        self.timestep += 1 \n",
    "        # Saving reward and is_terminal:\n",
    "        self.memory.rewards.append(reward)\n",
    "        self.memory.is_terminals.append(done)\n",
    "\n",
    "        # update if its time\n",
    "        if self.timestep % update_timestep == 0:\n",
    "            self.update()\n",
    "            self.memory.clear_memory()\n",
    "            self.timstamp = 0\n",
    "\n",
    "    def act(self, state):\n",
    "        return self.policy_old.act(state, self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9589b51c",
   "metadata": {},
   "source": [
    "### 训练PPO agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52e1c421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards looks like  (409,)\n",
      "rewards looks like  (397,)\n",
      "rewards looks like  (373,)\n",
      "rewards looks like  (434,)\n",
      "rewards looks like  (386,)\n",
      "rewards looks like  (469,)\n",
      "rewards looks like  (451,)\n",
      "rewards looks like  (471,)\n",
      "rewards looks like  (429,)\n",
      "rewards looks like  (413,)\n",
      "rewards looks like  (407,)\n",
      "rewards looks like  (567,)\n",
      "rewards looks like  (404,)\n",
      "rewards looks like  (461,)\n",
      "rewards looks like  (472,)\n",
      "rewards looks like  (467,)\n",
      "rewards looks like  (542,)\n",
      "rewards looks like  (490,)\n",
      "rewards looks like  (469,)\n",
      "rewards looks like  (469,)\n",
      "rewards looks like  (436,)\n",
      "rewards looks like  (577,)\n",
      "rewards looks like  (726,)\n",
      "rewards looks like  (537,)\n",
      "rewards looks like  (501,)\n",
      "rewards looks like  (541,)\n",
      "rewards looks like  (563,)\n",
      "rewards looks like  (458,)\n",
      "rewards looks like  (557,)\n",
      "rewards looks like  (548,)\n",
      "rewards looks like  (540,)\n",
      "rewards looks like  (454,)\n",
      "rewards looks like  (479,)\n",
      "rewards looks like  (497,)\n",
      "rewards looks like  (476,)\n",
      "rewards looks like  (428,)\n",
      "rewards looks like  (447,)\n",
      "rewards looks like  (472,)\n",
      "rewards looks like  (418,)\n",
      "rewards looks like  (419,)\n",
      "rewards looks like  (458,)\n",
      "rewards looks like  (428,)\n",
      "rewards looks like  (499,)\n",
      "rewards looks like  (397,)\n",
      "rewards looks like  (485,)\n",
      "rewards looks like  (498,)\n",
      "rewards looks like  (499,)\n",
      "rewards looks like  (516,)\n",
      "rewards looks like  (492,)\n",
      "rewards looks like  (503,)\n",
      "rewards looks like  (537,)\n",
      "rewards looks like  (460,)\n",
      "rewards looks like  (578,)\n",
      "rewards looks like  (558,)\n",
      "rewards looks like  (549,)\n",
      "rewards looks like  (743,)\n",
      "rewards looks like  (581,)\n",
      "rewards looks like  (588,)\n",
      "rewards looks like  (943,)\n",
      "rewards looks like  (763,)\n",
      "rewards looks like  (719,)\n",
      "rewards looks like  (639,)\n",
      "rewards looks like  (748,)\n",
      "rewards looks like  (697,)\n",
      "rewards looks like  (1625,)\n",
      "rewards looks like  (1102,)\n",
      "rewards looks like  (864,)\n",
      "rewards looks like  (912,)\n",
      "rewards looks like  (1971,)\n",
      "rewards looks like  (912,)\n",
      "rewards looks like  (1717,)\n",
      "rewards looks like  (2054,)\n",
      "rewards looks like  (2408,)\n",
      "rewards looks like  (1332,)\n",
      "rewards looks like  (2592,)\n",
      "rewards looks like  (1783,)\n",
      "rewards looks like  (771,)\n",
      "rewards looks like  (1553,)\n",
      "rewards looks like  (3208,)\n",
      "rewards looks like  (2987,)\n",
      "rewards looks like  (3389,)\n",
      "rewards looks like  (2100,)\n",
      "rewards looks like  (3430,)\n",
      "rewards looks like  (3505,)\n",
      "rewards looks like  (3511,)\n",
      "rewards looks like  (1869,)\n",
      "rewards looks like  (1516,)\n",
      "rewards looks like  (4127,)\n",
      "rewards looks like  (520,)\n",
      "rewards looks like  (540,)\n",
      "rewards looks like  (1457,)\n",
      "rewards looks like  (1442,)\n",
      "rewards looks like  (1451,)\n",
      "rewards looks like  (2347,)\n",
      "rewards looks like  (3304,)\n",
      "rewards looks like  (3229,)\n",
      "rewards looks like  (2454,)\n",
      "rewards looks like  (3335,)\n",
      "rewards looks like  (1256,)\n",
      "rewards looks like  (1565,)\n",
      "rewards looks like  (2094,)\n",
      "rewards looks like  (2340,)\n",
      "rewards looks like  (2413,)\n",
      "rewards looks like  (3192,)\n",
      "rewards looks like  (3834,)\n",
      "rewards looks like  (2361,)\n",
      "rewards looks like  (1502,)\n",
      "rewards looks like  (4161,)\n",
      "rewards looks like  (3331,)\n",
      "rewards looks like  (3458,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (3345,)\n",
      "rewards looks like  (4154,)\n",
      "rewards looks like  (1636,)\n",
      "rewards looks like  (2535,)\n",
      "rewards looks like  (2465,)\n",
      "rewards looks like  (3278,)\n",
      "rewards looks like  (2579,)\n",
      "rewards looks like  (2303,)\n",
      "rewards looks like  (3266,)\n",
      "rewards looks like  (2555,)\n",
      "rewards looks like  (3294,)\n",
      "rewards looks like  (1592,)\n",
      "rewards looks like  (4189,)\n",
      "rewards looks like  (2508,)\n",
      "rewards looks like  (4128,)\n",
      "rewards looks like  (2520,)\n",
      "rewards looks like  (3345,)\n",
      "rewards looks like  (4236,)\n",
      "rewards looks like  (2246,)\n",
      "rewards looks like  (3440,)\n",
      "rewards looks like  (3557,)\n",
      "rewards looks like  (4220,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (3381,)\n",
      "rewards looks like  (1726,)\n",
      "rewards looks like  (4161,)\n",
      "rewards looks like  (4161,)\n",
      "rewards looks like  (3351,)\n",
      "rewards looks like  (3378,)\n",
      "rewards looks like  (3379,)\n",
      "rewards looks like  (4198,)\n",
      "rewards looks like  (4197,)\n",
      "rewards looks like  (4176,)\n",
      "rewards looks like  (4225,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (4211,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (4244,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (3499,)\n",
      "rewards looks like  (4227,)\n",
      "rewards looks like  (3380,)\n",
      "rewards looks like  (3393,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (2628,)\n",
      "rewards looks like  (4231,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (3490,)\n",
      "rewards looks like  (1769,)\n",
      "rewards looks like  (3079,)\n",
      "rewards looks like  (2518,)\n",
      "rewards looks like  (4182,)\n",
      "rewards looks like  (3612,)\n",
      "rewards looks like  (3309,)\n",
      "rewards looks like  (1869,)\n",
      "rewards looks like  (3539,)\n",
      "rewards looks like  (4177,)\n",
      "rewards looks like  (4194,)\n",
      "rewards looks like  (4250,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (5000,)\n",
      "rewards looks like  (4335,)\n",
      "rewards looks like  (4578,)\n",
      "rewards looks like  (4029,)\n",
      "rewards looks like  (2280,)\n",
      "rewards looks like  (1020,)\n",
      "rewards looks like  (2053,)\n",
      "rewards looks like  (1593,)\n",
      "rewards looks like  (1549,)\n",
      "rewards looks like  (1171,)\n",
      "rewards looks like  (1973,)\n",
      "rewards looks like  (1150,)\n",
      "rewards looks like  (2596,)\n",
      "rewards looks like  (1438,)\n",
      "rewards looks like  (1236,)\n",
      "rewards looks like  (1329,)\n",
      "rewards looks like  (1718,)\n",
      "rewards looks like  (1325,)\n",
      "rewards looks like  (1265,)\n",
      "rewards looks like  (1858,)\n",
      "rewards looks like  (1237,)\n",
      "rewards looks like  (1615,)\n",
      "rewards looks like  (1947,)\n",
      "rewards looks like  (1581,)\n",
      "rewards looks like  (1333,)\n",
      "rewards looks like  (1350,)\n",
      "rewards looks like  (2020,)\n",
      "rewards looks like  (1281,)\n",
      "rewards looks like  (1600,)\n",
      "rewards looks like  (1444,)\n",
      "rewards looks like  (1487,)\n",
      "rewards looks like  (1535,)\n",
      "rewards looks like  (1247,)\n",
      "rewards looks like  (1975,)\n",
      "rewards looks like  (1701,)\n",
      "rewards looks like  (1251,)\n",
      "rewards looks like  (1181,)\n",
      "rewards looks like  (1123,)\n",
      "rewards looks like  (1566,)\n",
      "rewards looks like  (1233,)\n",
      "rewards looks like  (1122,)\n",
      "rewards looks like  (1191,)\n",
      "rewards looks like  (920,)\n",
      "rewards looks like  (1257,)\n",
      "rewards looks like  (1281,)\n",
      "rewards looks like  (2047,)\n",
      "rewards looks like  (1500,)\n",
      "rewards looks like  (2395,)\n",
      "rewards looks like  (1951,)\n",
      "rewards looks like  (1657,)\n",
      "rewards looks like  (2243,)\n",
      "rewards looks like  (1396,)\n",
      "rewards looks like  (2214,)\n",
      "rewards looks like  (1585,)\n",
      "rewards looks like  (1645,)\n",
      "rewards looks like  (2106,)\n",
      "rewards looks like  (1298,)\n",
      "rewards looks like  (1859,)\n",
      "rewards looks like  (2519,)\n",
      "rewards looks like  (1472,)\n",
      "rewards looks like  (2452,)\n",
      "rewards looks like  (1193,)\n",
      "rewards looks like  (1931,)\n",
      "rewards looks like  (1106,)\n",
      "rewards looks like  (1415,)\n",
      "rewards looks like  (1354,)\n",
      "rewards looks like  (1319,)\n",
      "rewards looks like  (1883,)\n",
      "rewards looks like  (1544,)\n",
      "rewards looks like  (1537,)\n",
      "rewards looks like  (1818,)\n",
      "rewards looks like  (1320,)\n",
      "rewards looks like  (1353,)\n",
      "rewards looks like  (1230,)\n",
      "rewards looks like  (1817,)\n",
      "rewards looks like  (1163,)\n",
      "rewards looks like  (1370,)\n",
      "rewards looks like  (1450,)\n",
      "rewards looks like  (1827,)\n",
      "rewards looks like  (1067,)\n",
      "rewards looks like  (1431,)\n",
      "rewards looks like  (1505,)\n",
      "rewards looks like  (1425,)\n",
      "rewards looks like  (846,)\n",
      "rewards looks like  (1374,)\n",
      "rewards looks like  (1127,)\n",
      "rewards looks like  (1698,)\n",
      "rewards looks like  (1504,)\n",
      "rewards looks like  (1428,)\n",
      "rewards looks like  (1255,)\n",
      "rewards looks like  (2629,)\n",
      "rewards looks like  (1249,)\n",
      "rewards looks like  (2138,)\n",
      "rewards looks like  (2827,)\n",
      "rewards looks like  (1400,)\n",
      "rewards looks like  (2334,)\n",
      "rewards looks like  (1813,)\n",
      "rewards looks like  (2928,)\n",
      "rewards looks like  (1326,)\n",
      "rewards looks like  (1253,)\n",
      "rewards looks like  (2661,)\n",
      "rewards looks like  (1083,)\n",
      "rewards looks like  (1858,)\n",
      "rewards looks like  (2108,)\n",
      "rewards looks like  (1386,)\n",
      "rewards looks like  (2252,)\n",
      "rewards looks like  (2316,)\n",
      "rewards looks like  (1283,)\n",
      "rewards looks like  (1763,)\n",
      "rewards looks like  (1131,)\n",
      "rewards looks like  (1456,)\n",
      "rewards looks like  (1154,)\n",
      "rewards looks like  (1968,)\n",
      "rewards looks like  (1242,)\n",
      "rewards looks like  (2033,)\n",
      "rewards looks like  (1344,)\n",
      "rewards looks like  (2075,)\n",
      "rewards looks like  (2193,)\n",
      "rewards looks like  (1314,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards looks like  (1063,)\n",
      "rewards looks like  (1262,)\n",
      "rewards looks like  (1375,)\n",
      "rewards looks like  (1491,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state_dim = 8 ### 游戏的状态是个8维向量\n",
    "action_dim = 4 ### 游戏的输出有4个取值\n",
    "n_latent_var = 256           # 神经元个数\n",
    "update_timestep = 1200      # 每多少补跟新策略\n",
    "lr = 0.002                  # learning rate\n",
    "betas = (0.9, 0.999)\n",
    "gamma = 0.99                # discount factor\n",
    "K_epochs = 4                # update policy for K epochs\n",
    "eps_clip = 0.2              # clip parameter for PPO  论文中表明0.2效果不错\n",
    "random_seed = 1 \n",
    "\n",
    "agent = PPOAgent(state_dim ,action_dim,n_latent_var,lr,betas,gamma,K_epochs,eps_clip)\n",
    "# agent.network.train()  # Switch network into training mode \n",
    "EPISODE_PER_BATCH = 5  # update the  agent every 5 episode\n",
    "NUM_BATCH = 300     # totally update the agent for 300 time\n",
    "\n",
    "\n",
    "avg_total_rewards, avg_final_rewards = [], []\n",
    "\n",
    "# prg_bar = tqdm(range(NUM_BATCH))\n",
    "for i in range(NUM_BATCH):\n",
    "\n",
    "    log_probs, rewards = [], []\n",
    "    total_rewards, final_rewards = [], []\n",
    "    values    = []\n",
    "    masks     = []\n",
    "    entropy = 0\n",
    "    # collect trajectory\n",
    "    for episode in range(EPISODE_PER_BATCH):\n",
    "        ### 重开一把游戏\n",
    "        state = env.reset()[0]\n",
    "        total_reward, total_step = 0, 0\n",
    "        seq_rewards = []\n",
    "        for i in range(1000):  ###游戏未结束\n",
    "\n",
    "            action = agent.act(state) ### 按照策略网络输出的概率随机采样一个动作\n",
    "            next_state, reward, done, _, _ = env.step(action) ### 与环境state进行交互，输出reward 和 环境next_state\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            total_step += 1     \n",
    "            rewards.append(reward) ### 记录每一个动作的reward\n",
    "            agent.step(reward, done)   \n",
    "            if done:  ###游戏结束\n",
    "                final_rewards.append(reward)\n",
    "                total_rewards.append(total_reward)\n",
    "                break\n",
    "\n",
    "    print(f\"rewards looks like \", np.shape(rewards))  \n",
    "    if len(final_rewards)> 0 and len(total_rewards) > 0:\n",
    "        avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
    "        avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
    "        avg_total_rewards.append(avg_total_reward)\n",
    "        avg_final_rewards.append(avg_final_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed36279",
   "metadata": {},
   "source": [
    "### PPO agent在玩5把游戏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcf27d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fix(env, seed)\n",
    "agent.policy.eval() # set the network into evaluation mode\n",
    "test_total_reward = []\n",
    "for i in range(5):\n",
    "    actions = []\n",
    "    state = env.reset()[0]\n",
    "    img = plt.imshow(env.render())\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done :\n",
    "        action= agent.act(state)\n",
    "        actions.append(action)\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        img.set_data(env.render())\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "    test_total_reward.append(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "110f555f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.001243596218075,\n",
       " 288.80299821616137,\n",
       " 229.40816702966168,\n",
       " -90.39667459390566,\n",
       " 310.07656187403023]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b66145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
